# Техническое видение проекта

## 1. Технологии

### Основной стек
- **Язык программирования**: Python
- **Telegram API**: aiogram
- **LLM провайдер**: openrouter через openai client
- **База данных**: не используется (все данные заложены в промпте)
- **Хранение данных**: Встроенные структуры Python (dist/list) для хранения истории диалога
- **Деплой**: Docker
- **Тестирование**: pytest
- **Управление зависимостями и окружением**: uv
- **Автоматизация сборки, запуска, деплоя**: make

### Обоснование выбора
- **aiogram** - современная асинхронная библиотека для Telegram Bot API
- **openrouter** - предоставляет доступ к различным LLM через единый API
- **uv** - быстрый и современный инструмент для управления Python окружением
- **Docker** - обеспечивает консистентность развертывания
- **make** - простой инструмент автоматизации для стандартных операций

## 2. Принципы разработки

### Основные принципы
1. **KISS (Keep It Simple, Stupid)** - максимальная простота решений
2. **Минимальная жизнеспособная версия (MVP)** - сначала базовый функционал, потом улучшения
3. **Функциональное программирование** - архитектура на функциях без ООП
4. **Единственная ответственность** - каждый модуль делает одну вещь хорошо
5. **Конфигурация через переменные окружения** - легко менять настройки без пересборки

### Управление состоянием и памятью
- **История диалогов**: хранение в памяти в Python структурах (dict/list)
- **Время хранения**: 24 часа с момента последнего сообщения пользователя
- **Размер истории**: ограничение в 10 сообщений на пользователя
- **Изоляция пользователей**: каждый пользователь имеет отдельную историю
- **Автоочистка**: автоматическое удаление истории через 24 часа бездействия

### Обработка ошибок
- **Пользовательские ошибки**: дружелюбные сообщения без технических деталей
- **Системные ошибки**: логирование в файлы для разработчика
- **Fallback**: при недоступности LLM - информирование пользователя о временной проблеме

## 3. Структура проекта

```
llmstart_test_1/
├── src/                          # Основной код приложения
│   ├── bot/                      # Логика телеграм-бота
│   │   ├── handlers.py           # Обработчики сообщений
│   │   └── middleware.py         # Промежуточная обработка
│   ├── llm/                      # Работа с LLM
│   │   ├── client.py             # Клиент для openrouter
│   │   └── prompts.py            # Загрузка системных промптов
│   ├── memory/                   # Управление историей диалогов
│   │   └── storage.py            # Хранение и очистка истории
│   ├── config/                   # Конфигурация
│   │   └── settings.py           # Настройки из переменных окружения
│   └── main.py                   # Точка входа в приложение
├── prompts/                      # Системные промпты
│   └── system_prompt.txt         # Основной системный промпт
├── tests/                        # Тесты pytest
│   ├── test_bot/                 # Тесты бота
│   ├── test_llm/                 # Тесты LLM интеграции
│   └── test_memory/              # Тесты памяти
├── docker/                       # Docker конфигурация
│   └── Dockerfile
├── doc/                          # Документация проекта
│   ├── product_idea.md
│   ├── vision.md
│   └── README.md
├── Makefile                      # Автоматизация команд
├── pyproject.toml                # Конфигурация uv и проекта
├── .env.example                  # Пример переменных окружения
└── README.md                     # Основной README
```

### Принципы организации
- **Функциональное разделение**: каждая папка отвечает за одну область
- **Один файл - одна ответственность**: handlers.py только обрабатывает сообщения
- **Внешние ресурсы отдельно**: промпты в текстовых файлах вне кода
- **Тестируемость**: структура тестов повторяет структуру src/
- **Логирование**: в стандартный вывод для совместимости с Docker

## 4. Архитектура проекта

### Поток данных
```
Пользователь → Telegram → Bot Handler → Memory Check → LLM Client → OpenRouter → Response
     ↑                         ↓              ↓                           ↓
     └── Ответ ←─── Validation ←─── Memory Update ←─── Обработка ←──────────┘
```

### Основные компоненты

#### 1. Bot Handler (`handlers.py`)
- **Функции**: прием и маршрутизация сообщений от Telegram
- **Команды**: 
  - `/start` - приветствие и описание возможностей
  - `/help` - инструкция по использованию
  - Текстовые сообщения - обработка консультационных запросов
- **Валидация**: проверка длины сообщения (максимум 1000 символов)

#### 2. Memory Manager (`storage.py`)
- **Функции**: управление историей диалогов пользователей
- **Операции**:
  - Загрузка истории пользователя (последние 10 сообщений)
  - Добавление нового сообщения в историю
  - Автоочистка историй старше 24 часов
- **Структура данных**: `dict[user_id] -> list[{"role": "user/assistant", "content": "text", "timestamp": datetime}]`

#### 3. LLM Client (`client.py`)
- **Функции**: взаимодействие с OpenRouter API
- **Операции**:
  - Загрузка системного промпта из файла
  - Формирование запроса (системный промпт + история + новое сообщение)
  - Отправка запроса в OpenRouter
  - Обработка ответа
- **Retry-логика**: 3 попытки при сбоях, затем уведомление пользователя

#### 4. Configuration Manager (`settings.py`)
- **Функции**: загрузка настроек из переменных окружения
- **Настройки**:
  - `TELEGRAM_BOT_TOKEN` - токен бота
  - `OPENROUTER_API_KEY` - ключ API OpenRouter
  - `OPENROUTER_MODEL` - модель для использования
  - `MAX_MESSAGE_LENGTH` - максимальная длина сообщения (1000)
  - `MEMORY_TTL_HOURS` - время жизни истории (24)
  - `MAX_HISTORY_SIZE` - размер истории (10)

### Принципы взаимодействия
- **Функциональная композиция**: каждый компонент - набор функций
- **Единый поток данных**: линейная обработка без сложных зависимостей
- **Независимость компонентов**: модули не знают друг о друге напрямую
- **Graceful degradation**: система работает даже при частичных сбоях

## 5. Модель данных

### Структуры данных в памяти

#### 1. История диалогов
```python
# Глобальная структура в памяти
user_sessions: dict[int, UserSession] = {}

# Структура сессии пользователя
UserSession = {
    "user_id": int,             # ID пользователя в Telegram
    "user_name": str,           # Имя пользователя для персонального обращения
    "history": list[Message],   # Последние 10 сообщений
    "last_activity": datetime,  # Время последней активности
    "created_at": datetime      # Время создания сессии
}

# Структура сообщения
Message = {
    "role": str,        # "user" или "assistant"
    "content": str,     # Текст сообщения  
    "timestamp": datetime
}
```

#### 2. Конфигурация приложения
```python
Config = {
    "TELEGRAM_BOT_TOKEN": str,      # Токен Telegram бота
    "OPENROUTER_API_KEY": str,      # Ключ API OpenRouter
    "OPENROUTER_MODEL": str,        # Модель LLM (например, "anthropic/claude-3.5-sonnet")
    "MAX_MESSAGE_LENGTH": int,      # Максимальная длина сообщения (1000)
    "MEMORY_TTL_HOURS": int,        # Время жизни истории в часах (24)
    "MAX_HISTORY_SIZE": int,        # Максимальный размер истории (10)
    "CLEANUP_INTERVAL_HOURS": int   # Интервал очистки памяти (6)
}
```

### Принципы работы с данными
- **Простота**: минимальный набор полей для функциональности
- **Персонализация**: сохранение имени для дружелюбного общения
- **Автоочистка**: удаление неактивных сессий каждые 6 часов
- **Ограничения**: контроль размера истории и времени жизни
- **Безопасность**: данные существуют только в памяти, не персистентны

## 6. Работа с LLM

### Конфигурация LLM
- **Провайдер**: OpenRouter API
- **Основная модель**: `qwen/qwen-2.5-72b-instruct:free` (бесплатная)
- **Резервная модель**: `deepseek/deepseek-chat-v3.1:free` (бесплатная)
- **Формат**: OpenAI-совместимый API через OpenRouter

### Настраиваемые параметры
```python
LLM_Config = {
    "PRIMARY_MODEL": str,       # qwen/qwen-2.5-72b-instruct:free
    "FALLBACK_MODEL": str,      # deepseek/deepseek-chat-v3.1:free
    "TEMPERATURE": float,       # 0.7 (по умолчанию, настраиваемо)
    "MAX_TOKENS": int,          # 1500 (по умолчанию, настраиваемо)
    "TOP_P": float,            # 0.9 (по умолчанию, настраиваемо)
    "RETRY_ATTEMPTS": int       # 3 (количество повторных попыток)
}
```

### Структура запроса к LLM
1. **Системный промпт** (загружается из `prompts/system_prompt.txt`)
2. **История диалога** (последние 10 сообщений в формате OpenAI)
3. **Новое сообщение пользователя**

### Логика переключения моделей
- **Основная модель**: первая попытка на `qwen/qwen-2.5-72b-instruct:free`
- **Retry с основной**: 2 дополнительные попытки на основной модели
- **Fallback**: при исчерпании попыток переключение на резервную модель
- **Финальная ошибка**: если резервная модель тоже недоступна

### Обработка ответов
- **Валидация**: проверка статуса HTTP и структуры ответа
- **Извлечение контента**: получение текста из response.choices[0].message.content
- **Обработка ошибок**: логирование и user-friendly сообщения об ошибках
- **Timeout**: ограничение времени ожидания ответа (30 секунд)

## 7. Мониторинг

### Принципы мониторинга
- **Минимализм**: только критически важная информация
- **Простота**: логирование в стандартный вывод
- **Отсутствие внешних зависимостей**: никаких внешних систем мониторинга

### Отслеживаемые метрики
```python
# Счетчики в памяти
Metrics = {
    "requests_total": int,          # Общее количество запросов
    "requests_errors": int,         # Количество ошибок
    "llm_response_times": list,     # Времена ответа LLM (для расчета среднего)
    "active_users_today": set,      # Уникальные пользователи за день
    "memory_sessions_count": int,   # Количество активных сессий
    "startup_time": datetime        # Время запуска бота
}
```

### Логируемые события
1. **Системные события**:
   - Запуск/остановка бота
   - Ошибки подключения к Telegram API
   - Ошибки подключения к OpenRouter API
   - Превышение лимитов (длина сообщений)

2. **Статистика** (каждый час):
   - Количество запросов за час
   - Среднее время ответа LLM
   - Количество ошибок за час
   - Количество активных сессий

3. **Ошибки**:
   - Недоступность LLM моделей
   - Исключения в коде приложения
   - Превышение лимитов OpenRouter

### Формат логирования
```
[TIMESTAMP] [LEVEL] [COMPONENT] Message
[2024-09-18 10:30:00] [INFO] [BOT] Bot started successfully
[2024-09-18 10:30:15] [ERROR] [LLM] OpenRouter API error: 429 Too Many Requests
[2024-09-18 11:00:00] [INFO] [STATS] Hourly stats: 45 requests, 1.2s avg response, 2 errors
```

### Отсутствие внешних систем
- **Нет алертов**: система не отправляет уведомления
- **Нет dashboard**: только логи в stdout
- **Нет метрик в файлах**: все данные в памяти и логах

## 8. Сценарии работы

### Основные сценарии использования

#### 1. Первый запуск бота (/start)
```
Добро пожаловать! 👋

Я - ваш ИИ-консультант по формулировке целей обучения.

🎯 Помогаю составлять учебные цели по таксономии Блума:
• Знание (запоминание фактов)
• Понимание (объяснение концепций)  
• Применение (использование на практике)
• Анализ (разбор на части)
• Синтез (создание нового)
• Оценка (критическое мышление)

📝 Просто опишите тематику, а также чего вы ожидаете от обучаемых после прохождения обучения, и я помогу сформулировать конкретные, измеримые цели обучения.

Пример: "Тематика - охрана труда на производстве". 
Обучаемый должен (варианты):
• уметь воспроизводить полученную информацию
• объяснить ее своими словами, обобщить или пересказать  
• использовать на практике полученные знания
• уметь разбивать информацию на составные части, видеть скрытые мотивы и причины
• создать новый продукт (изделие, программу)
• способен высказывать собственное мнение, делать выводы
```

#### 2. Новая консультация (без истории)
**Пользователь**: "Аудиторное занятие по теме - Охрана труда на производстве"
**Бот**: Задает уточняющие вопросы:
- Для какой аудитории? (возраст, уровень подготовки)
- Какой уровень таксономии Блума планируете (знание, понимание, применение, анализ, синтез, оценка)?
- Продолжительность занятия/курса?
- Есть ли у вас есть практические задания?
- Как будете оценивать достижение целей?
- На какой документ (источник информации) опираетесь при проведении занятия? (просто без расшифровки укажите "в соответствии с инструкцией...", "в соответствии с положением...", и т.д.)

#### 3. Продолжение консультации (с историей)
**Пользователь**: "А как сформулировать цели для практических занятий?"
**Бот**: Отвечает с учетом предыдущего контекста (охране труда на предприятии)

#### 4. Справка (/help)
```
📖 Примеры вопросов:

"Помогите сформулировать цели обучения по основам промышленной безопасности в соответствии с законодательством. Обучаемый должен уметь воспроизводить (повторить) полученную информацию."

"Нужны цели для практического занятия по использованию огнетущителя ОУ. Обучаемые должны уметь применять на практике полученные знания"

"Как составить цели обучения для аудиторного занятия по теме - Порядок действий при пожаре. Обучаемые должны объяснить своими словами, обобщить или пересказать"
```

#### 5. Обработка ошибок и ограничений
- **Длинное сообщение**: "Сообщение слишком длинное, сократите до 1000 символов"
- **Вопросы не по теме**: "Извините, я специализируюсь только на помощи в формулировке целей обучения по таксономии Блума. Пожалуйста, расскажите о вашем курсе или занятии."
- **Недоступность LLM**: "Сервис временно недоступен, попробуйте повторить запрос через несколько минут"

### Принципы взаимодействия
- **Фокус на таксономии Блума**: все рекомендации основаны на 6 уровнях когнитивного развития
- **Персонализация**: обращение по имени, учет контекста беседы
- **Пошаговое уточнение**: от общих вопросов к конкретным формулировкам
- **Практическая применимость**: цели должны быть измеримыми и достижимыми

## 9. Деплой

### Рекомендуемая платформа
**Railway**
- **Стоимость**: $5 кредитов в месяц бесплатно (~100 часов работы)
- **Ресурсы**: до 512MB RAM, 1GB диск
- **Простота**: автодеплой из GitHub из коробки
- **Скорость настройки**: 5 минут от регистрации до работающего бота
- **Поддержка**: Docker, переменные окружения, логи в реальном времени

### Автоматизация деплоя
**Railway встроенная интеграция с GitHub:**
1. **Подключение репозитория**: в веб-интерфейсе Railway
2. **Автодеплой**: при каждом push в main ветку
3. **Без конфигурации**: никаких GitHub Actions не требуется
4. **Логи**: доступны в реальном времени в веб-интерфейсе

**Процесс:**
```
git push origin main → Railway автоматически → Новая версия запущена
```

### Make команды для управления
```makefile
# Makefile
build:
	docker build -t llm-bot .

run:
	docker run -d --name llm-bot --restart=always --env-file .env llm-bot

restart:
	docker stop llm-bot || true
	docker rm llm-bot || true
	make build
	make run

stop:
	docker stop llm-bot
	docker rm llm-bot

logs:
	docker logs -f llm-bot

status:
	docker ps | grep llm-bot
```

### Docker конфигурация
```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY . .

RUN pip install uv
RUN uv sync

CMD ["uv", "run", "python", "src/main.py"]
```

### Процесс первичной настройки
1. **Регистрация**: создание аккаунта на Railway.app
2. **Подключение GitHub**: авторизация доступа к репозиториям
3. **Создание проекта**: выбор репозитория с ботом
4. **Настройка переменных**: добавление TELEGRAM_BOT_TOKEN, OPENROUTER_API_KEY и др.
5. **Автодеплой**: Railway автоматически соберет и запустит бота
6. **Мониторинг**: логи и метрики доступны в веб-интерфейсе

### Преимущества решения
- **Простота**: настройка за 5 минут без технических навыков
- **Auto-deploy**: автоматическое обновление при push в GitHub
- **Zero-config**: никаких Dockerfile или CI/CD настроек не требуется
- **Monitoring**: встроенные логи и метрики в веб-интерфейсе
- **Polling-friendly**: отлично подходит для Telegram polling ботов

## 10. Конфигурирование

### Переменные окружения (.env файл)

#### Обязательные (без значений по умолчанию)
```env
# .env файл (для локальной разработки и Railway)
# Секретные токены - скрываются в логах
TELEGRAM_BOT_TOKEN=your_bot_token_here     # Обязательно
OPENROUTER_API_KEY=your_openrouter_key     # Обязательно
```

#### Настраиваемые (со значениями по умолчанию)
```env
# LLM модели
PRIMARY_MODEL=qwen/qwen-2.5-72b-instruct:free          # default
FALLBACK_MODEL=deepseek/deepseek-chat-v3.1:free        # default

# LLM параметры
TEMPERATURE=0.7          # default (можно изменить 0.0-2.0)
MAX_TOKENS=1500          # default (можно изменить)
TOP_P=0.9               # default (можно изменить 0.0-1.0)
RETRY_ATTEMPTS=3        # default (можно изменить)

# Поведение бота
MAX_MESSAGE_LENGTH=1000      # default (можно изменить)
MEMORY_TTL_HOURS=24         # default (можно изменить)
MAX_HISTORY_SIZE=10         # default (можно изменить)
CLEANUP_INTERVAL_HOURS=6    # default (можно изменить)
```

### Валидация при запуске
```python
# Проверки при старте бота
1. Проверка обязательных токенов:
   - TELEGRAM_BOT_TOKEN не пустой
   - OPENROUTER_API_KEY не пустой

2. Проверка диапазонов значений:
   - TEMPERATURE от 0.0 до 2.0
   - MAX_TOKENS > 0
   - TOP_P от 0.0 до 1.0
   - Временные параметры > 0

3. Тест подключения:
   - Telegram API доступен
   - OpenRouter API работает с указанным ключом
```

### Способы конфигурирования

#### Локальная разработка:
- **Файл**: `.env` в корне проекта
- **Пример**: `.env.example` (без реальных токенов)
- **Загрузка**: автоматически через python-dotenv

#### Railway (продакшен):
- **Вариант 1**: загрузить .env файл через веб-интерфейс
- **Вариант 2**: указать переменные через Railway Variables
- **Рекомендация**: использовать .env файл для простоты

#### Администратор (ВЫ):
- **Настраивает**: все технические параметры через .env
- **Локально**: редактирует .env файл
- **На сервере**: загружает .env в Railway

#### Инструкторы (пользователи):
- **Настраивают**: ничего технического
- **Общаются**: только через Telegram с ботом
- **Указывают**: предмет, аудиторию, уровень Блума в диалоге

### Безопасность
- **Секретные данные**: только TELEGRAM_BOT_TOKEN и OPENROUTER_API_KEY
- **В логах**: токены отображаются как `TOKEN=******`
- **В коде**: никакие токены не hardcode в исходниках
- **В Railway**: переменные окружения автоматически защищены

## 11. Логгирование

### Уровни логирования
- **INFO**: запуск/остановка бота, статистика по часам
- **WARNING**: переключение на резервную модель, превышение лимитов
- **ERROR**: ошибки API, исключения в коде приложения
- **DEBUG**: детали для разработки (только в dev режиме)

### Формат логов
```
[TIMESTAMP] [LEVEL] [COMPONENT] Message
[2024-09-18 10:30:00] [INFO] [BOT] Bot started successfully
[2024-09-18 10:30:15] [ERROR] [LLM] OpenRouter API error: 429 Too Many Requests
[2024-09-18 11:00:00] [INFO] [STATS] Hourly: 45 requests, 1.2s avg, 2 errors, 12 users
```

### Что логируем ✅
- **Системные события**: запуск/остановка компонентов
- **Статистика**: количество запросов, время ответа, ошибки (без персональных данных)
- **Ошибки API**: проблемы с Telegram/OpenRouter
- **Переключения моделей**: fallback на резервную модель
- **User ID**: только числовой ID для отладки (например: user_12345)

### Что НЕ логируем ❌
- **Токены**: показываем как `TOKEN=******`
- **Сообщения пользователей**: полная приватность
- **Имена пользователей**: только ID для анонимности
- **API ключи**: скрываем в логах

### Railway интеграция
- **Автосбор**: логи автоматически собираются Railway
- **Реальное время**: доступны в веб-интерфейсе мгновенно
- **Поиск**: встроенная фильтрация по уровням и компонентам
- **Retention**: Railway автоматически управляет хранением

### Компоненты логирования
```python
# Структура логирования
[BOT] - события Telegram бота
[LLM] - работа с OpenRouter API  
[MEMORY] - управление историей диалогов
[CONFIG] - загрузка конфигурации
[STATS] - почасовая статистика
```

### Принципы логирования
- **Приватность**: никаких персональных данных пользователей
- **Отладка**: достаточно информации для диагностики проблем
- **Простота**: стандартный Python logging в stdout
- **Безопасность**: автоматическое скрытие секретных данных
